{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Questions to keep in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Predict the next order more specifically what item will the user purchase next\n",
    "2. What products will be 'discovered', what should be recommended based on prior purchases?\n",
    "3. What products could usually be purchased together, which items arent purchased together?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling/ Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'aisles.csv' does not exist: b'aisles.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b2287d63467b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maisles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"aisles.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdepartments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"departments.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0morders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"orders.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"order_products__prior.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"order_products__train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'aisles.csv' does not exist: b'aisles.csv'"
     ]
    }
   ],
   "source": [
    "aisles = pd.read_csv(\"aisles.csv\")\n",
    "departments = pd.read_csv(\"departments.csv\")\n",
    "orders = pd.read_csv(\"orders.csv\")\n",
    "prior = pd.read_csv(\"order_products__prior.csv\")\n",
    "train = pd.read_csv(\"order_products__train.csv\")\n",
    "products = pd.read_csv(\"products.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending train with prior to obtain whole sample size \n",
    "full = prior.append(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting values by order id to keep some structure\n",
    "full.sort_values(by = 'order_id', inplace = True, kind = 'mergesort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging orders and full to include time and product information\n",
    "full= full.merge(orders, on = 'order_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging to substitute id for actual name\n",
    "full = full.merge(products, on = 'product_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging to substitute id for actual name\n",
    "full = full.merge(aisles, on = 'aisle_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging to substitute id for actual name\n",
    "full = full.merge(departments, on = 'department_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing id in place of actual name \n",
    "full.pop('product_id')\n",
    "full.pop('aisle_id')\n",
    "full.pop('department_id')\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reordering sequence of columns for easy lookup\n",
    "full = full[[ 'order_id',\n",
    "             'order_number',\n",
    "             'user_id',\n",
    "             'department',\n",
    "             'aisle',\n",
    "             'product_name',\n",
    "             'add_to_cart_order',\n",
    "             'days_since_prior_order',\n",
    "             'order_dow',\n",
    "             'order_hour_of_day',\n",
    "             'reordered',\n",
    "             'eval_set']]\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storytelling, Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can we classify the items? produce offers the most\n",
    "# Will this be evident in the recommended products?\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.countplot(\n",
    "            y = 'department',\n",
    "            data = full,  \n",
    "            orient = 'h', \n",
    "            saturation = 0.5,\n",
    "            )\n",
    "plt.title('What department is purchased from the most?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many products are there?\n",
    "total_products = products.shape[0]\n",
    "total_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many aisles?\n",
    "total_aisles = aisles.shape[0]\n",
    "total_aisles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many departments?\n",
    "total_departments = departments.shape[0]\n",
    "total_departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of data for department and aisle comparison \n",
    "stock = full[['department', 'aisle', 'product_name']]\n",
    "# changed from series to df to input into graph\n",
    "total_units = pd.DataFrame(stock.groupby(['department','aisle']).size().sort_values())\n",
    "# renaming unnamed column\n",
    "total_units.reset_index(inplace = True)\n",
    "total_units.rename(columns = { 0:'totals'}, inplace = True)\n",
    "total_units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.loc[(full['aisle'] == 'missing') | (full['department'] == 'missing')]\n",
    "# 77396 observations contain \"missing\"  \n",
    "# because of the 1258 products containing \"missing\" in aisle and/or department column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization for better interpretation and quicker comparisons\n",
    "fig, ax = plt.subplots(figsize=(20,65), dpi= 325)\n",
    "# Initial setup for the background\n",
    "ax.hlines(\n",
    "          y=total_units.aisle, \n",
    "          color='gray', \n",
    "          xmin=350, \n",
    "          xmax=1050, \n",
    "          alpha=0.3,\n",
    "          linewidth=2,\n",
    "          linestyles='dashdot'\n",
    "          )\n",
    "\n",
    "plot_kws = {'s':500}\n",
    "# controls marker size passed down to plt.scatter at draw time\n",
    "sns.scatterplot(\n",
    "            x= 'totals',\n",
    "            y='aisle',\n",
    "            hue='department', \n",
    "            data=total_units, \n",
    "            palette= 'colorblind', \n",
    "            **plot_kws\n",
    "           )\n",
    "\n",
    "# Title, Label, Ticks and Legend\n",
    "\n",
    "ax.set_title(\n",
    "            'Product Aisle Items',\n",
    "             fontdict={'size':63}\n",
    "            )\n",
    "plt.legend(\n",
    "           loc = 'lower right',\n",
    "           prop={'size': 50},\n",
    "           markerscale = 5\n",
    "          )\n",
    "\n",
    "# x axis\n",
    "ax.set_xlim(0, 1300)\n",
    "ax.set_xlabel('Items Available', fontdict={'size':50})\n",
    "ax.set_xticklabels([0,200,400,600,800,1000,1200], fontdict = {'size': 36})\n",
    "ax.tick_params(axis = 'x', labelsize = 50, which = 'major')\n",
    "\n",
    "# y axis\n",
    "ax.tick_params(axis = 'y', labelsize = 25, which ='major')\n",
    "plt.ylabel('Aisle', fontdict = {'size':21})\n",
    "ax.set_yticks(total_units.aisle)\n",
    "ax.set_yticklabels(total_units.aisle.str.title(),\n",
    "                   fontdict={'horizontalalignment': 'right'})\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 20 products sold\n",
    "top_20_items = full.product_name.value_counts().head(20)\n",
    "top_20_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "ax.barh(\n",
    "    top_20_items.index,\n",
    "    top_20_items, \n",
    "    align='center'\n",
    "        )\n",
    "# labels read top-to-bottom\n",
    "ax.invert_yaxis() \n",
    "ax.set_xlabel('Amount Purchased')\n",
    "ax.set_title('What items are the most purchased?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What items are reordered the most? only a few slight differences\n",
    "reordered_amt = full.loc[full['reordered'] == 1].groupby('product_name').size()\n",
    "reordered_amt.sort_values(inplace = True, ascending = False)\n",
    "top_20_reordered = reordered_amt.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "ax.barh(top_20_reordered.index, top_20_reordered, align='center')\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Amount Reordered')\n",
    "ax.set_title('What items are reordered the most ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What items are usually chosen first?\n",
    "first_picks = full.loc[full['add_to_cart_order'] == 1].groupby('product_name').size()\n",
    "first_picks.sort_values(inplace = True, ascending = False)\n",
    "first_picks_top_20 = first_picks.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "ax.barh(first_picks_top_20.index,first_picks_top_20, align='center')\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Number of times chosen first')\n",
    "ax.set_title('What items are chosen first?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often is a product reordered\n",
    "reorder_ratio = full.reordered.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting pie chart, kwargs draws from pyplot.pie\n",
    "pie_kwargs = {'startangle': 90, \n",
    "              'labels' : ['Reordered','Not Reordered'],\n",
    "              'autopct' : '%.1f%%',\n",
    "               'fontsize' : 'x-large'\n",
    "             }\n",
    "reorder_ratio.plot(kind = 'pie', \n",
    "                   figsize = (8,8),\n",
    "                   title = 'Percentges of Items Reordered',\n",
    "                   shadow = True,\n",
    "                   **pie_kwargs).set_ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order amount per user\n",
    "order_amt = full.groupby('user_id').order_number.max()\n",
    "order_amt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order amount per user\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.distplot(\n",
    "            order_amt, \n",
    "            kde = True, \n",
    "            bins = 10, \n",
    "            color = 'chocolate', \n",
    "            axlabel = 'Amount of Purchases',\n",
    "            )\n",
    "plt.title('How many orders are there per user?')\n",
    "plt.ylabel('percentage')\n",
    "plt.axvline(order_amt.mean(), linestyle='dashed',)\n",
    "plt.text(\n",
    "    order_amt.mean() + 1,\n",
    "    0.08,\n",
    "    'mean = ' + str(round(order_amt.mean(), 2)),\n",
    "    verticalalignment = 'top'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of items purchased in each order\n",
    "items_per_purchase = full.groupby('order_id').add_to_cart_order.max()\n",
    "items_per_purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items per purchase\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.distplot(\n",
    "            items_per_purchase, \n",
    "            kde = True, \n",
    "            color = 'coral', \n",
    "            axlabel = 'Items per Purchase',\n",
    "            )\n",
    "plt.title('How many items are purchased each order?')\n",
    "plt.ylabel('percentage')\n",
    "plt.axvline(items_per_purchase.mean(), linestyle='dashed',)\n",
    "plt.text(18,\n",
    "         0.06,\n",
    "         'mean = '+ str(round(items_per_purchase.mean(), 2)),\n",
    "         verticalalignment = 'top'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_since_means = full.groupby('user_id').days_since_prior_order.mean()\n",
    "days_since_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items per purchase\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.distplot(\n",
    "            days_since_means, \n",
    "            kde = True, \n",
    "            color = 'chocolate', \n",
    "            axlabel = 'Mean of Days Since Last Order',\n",
    "            )\n",
    "plt.title('What is the mean amount of days since prior order')\n",
    "plt.ylabel('percentage')\n",
    "plt.axvline(days_since_means.mean(), linestyle='dashed',)\n",
    "plt.text(days_since_means.mean() + 2,\n",
    "         0.06,\n",
    "         'mean = '+ str(round(days_since_means.mean(), 2)),\n",
    "         verticalalignment = 'top'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot do the amount of days since person relate to the amount of orders made\n",
    "plt.figure(figsize = (10,10))\n",
    "\n",
    "plt.scatter(order_amt, days_since_means,  marker = 'o', alpha = 0.02)\n",
    "plt.plot(\n",
    "    orders.order_number.value_counts().index,\n",
    "    orders.groupby('order_number').days_since_prior_order.mean(),\n",
    "    color = 'b'\n",
    "        )\n",
    "plt.title('Amount of orders made vs mean amount of days since prior order')\n",
    "plt.xlabel('Number of orders made in the past')\n",
    "plt.ylabel('mean number of days since prior order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_times = orders.groupby([\"order_dow\", \"order_hour_of_day\"])[\"order_number\"].agg(\"count\").reset_index()\n",
    "order_times = order_times.pivot('order_hour_of_day', 'order_dow','order_number')\n",
    "order_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time of day vs day of week heatmap\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(order_times, robust = True)\n",
    "plt.title(\"Time of the Day vs. Day of the Week\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do the days compare to one another?\n",
    "dow = full.order_dow.value_counts()\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.stem(dow)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Amount of Orders')\n",
    "plt.xticks([0,1,2,3,4,5,6], ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "plt.title('What day has the most orders?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do the hours of the day compare?\n",
    "time_of_day = full.order_hour_of_day.value_counts(normalize = True).sort_index()\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.stem(time_of_day)\n",
    "plt.xlabel('Hour')\n",
    "plt.xticks([0,2,4,6,8,10,12,14,16,18,20,22])\n",
    "plt.ylabel('Percentage of Orders')\n",
    "plt.title('What are the peak hours?')\n",
    "plt.axhline(y = 0.01, linewidth = 0.5, linestyle = '--', color = 'magenta' )\n",
    "plt.text(x = 0, y = 0.015, s = ' 10% of orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organic foods seem very popular\n",
    "organic_yn = full[['order_id', 'product_name', 'reordered']]\n",
    "organic_yn['Is it organic?'] = organic_yn['product_name'].str.contains('Organic', case = False)\n",
    "organic_yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many purchases are organic?\n",
    "organic_yn['Is it organic?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a table used to consolidate and plot reorder vs organic \n",
    "organic_table = organic_yn.pivot_table(\n",
    "    'order_id',\n",
    "    'Is it organic?',\n",
    "    'reordered',\n",
    "    aggfunc = 'count'\n",
    "    )\n",
    "organic_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organic_table.plot(kind = 'bar')\n",
    "plt.ylabel('millions')\n",
    "plt.title('Do organic foods get reordered more often?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if organic foods do get reordered more often a hypothesis test will be conducted. \n",
    "significance = 0.01.\n",
    "\n",
    "H0 - Organic food does not have a greater likelyhood of being reordered.     \n",
    "Ha - Organic food does have a greater likelyhood of being reordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organic_table.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for beta distribution\n",
    "success_a = organic_table.iloc[1][1]\n",
    "failure_a = organic_table.iloc[1][0]\n",
    "success_b = organic_table.iloc[0][1]\n",
    "failure_b = organic_table.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples\n",
    "a_samples_beta = np.random.beta(success_a, failure_a, 1000)\n",
    "b_samples_beta = np.random.beta(success_b, failure_b, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas series for better handling later\n",
    "a_samples_beta = pd.Series(a_samples_beta)\n",
    "b_samples_beta = pd.Series(b_samples_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the two distributions using kernel density estimation\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'Organic': a_samples_beta,\n",
    "        'Not Organic': b_samples_beta,\n",
    "\n",
    "    }\n",
    ").plot(\n",
    "    kind='kde',\n",
    "    title='Beta Distribution',\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined graph wasn't effective for individual distribution and shows significant difference\n",
    "a_samples_beta.hist()\n",
    "plt.title('beta distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check shape of distrbution\n",
    "b_samples_beta.hist()\n",
    "plt.title('beta distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " str(100 * ((a_samples_beta - b_samples_beta) > 0).mean()) + '% Confident in organic having better rate of reorder.' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis has been rejected therefore, it can be assumed that organic foods have a higher likelihood of probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "significance = 0.01\n",
    "\n",
    "H0 - Orders that are picked first have no relationship to reorder status\n",
    "\n",
    "Ha - Orders that are picked first have a relationship with reorder status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequentist type hypothesis test\n",
    "first_picks = full.loc[full['add_to_cart_order'] == 1]\n",
    "reordered_first_picks = first_picks.loc[first_picks['reordered'] == 1]\n",
    "not_reordered_first_picks = first_picks.loc[first_picks['reordered'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_test(df1, df2):\n",
    "    \"\"\"Tests the hypotheses with product name only\"\"\"\n",
    "    mean1 = df1.product_name.value_counts().mean() \n",
    "    mean2 = df2.product_name.value_counts().mean()\n",
    "    # calculate the mean \n",
    "    var1 = df1.product_name.value_counts().var()\n",
    "    var2 = df2.product_name.value_counts().var()\n",
    "    # calculate the variance\n",
    "    length1 = df1.product_name.value_counts().shape[0]\n",
    "    length2 = df2.product_name.value_counts().shape[0]\n",
    "    # obtain length of value_counts\n",
    "    var_pop_est = (((length1 - 1) * var1) + ((length2 - 1) * var2)) / length1 + length2 -2\n",
    "    # variance population estimate (pooled)\n",
    "    SE_diff = np.sqrt(var_pop_est) * (np.sqrt((1 / length1) + 1 / length2))\n",
    "    # standard error for difference\n",
    "    mean_diff = mean1 - mean2\n",
    "    # calculate difference of means\n",
    "    lower_interval = mean_diff - 2.576 * SE_diff\n",
    "    upper_interval = mean_diff + 2.576 * SE_diff\n",
    "  \n",
    "    return lower_interval, upper_interval, (mean_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep in variable to access values later\n",
    "hypothesis_test(reordered_first_picks, not_reordered_first_picks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence interval does not contain zero within and therefore the null hypothesis is rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "significance = 0.01\n",
    "\n",
    "H0 - Any order picked will have no relationship to reorder status\n",
    "\n",
    "Ha - Any order picked will have a relationship to reorder status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reordered = full.loc[full['reordered'] == 1]\n",
    "not_reordered = full.loc[full['reordered'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_test(reordered, not_reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "top_30_purchases = full.product_name.value_counts().head(30)\n",
    "top_30_reorders = reordered_amt.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples\n",
    "purchase_samples1 = np.random.dirichlet(top_30_purchases)\n",
    "reorder_samples1 = np.random.dirichlet(top_30_reorders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert to pandas series\n",
    "purchase_samples1 = pd.Series(purchase_samples1)\n",
    "reorder_samples1 = pd.Series(reorder_samples1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        'Purchase': purchase_samples1,\n",
    "        'Reorder': reorder_samples1,\n",
    "\n",
    "    }\n",
    ").plot(\n",
    "    kind='kde',\n",
    "    title='Beta Distribution',\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples\n",
    "purchase_samples2 = np.random.multinomial(30, purchase_samples1)\n",
    "reorder_samples2 = np.random.multinomial(30, reorder_samples1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert to pandas series\n",
    "purchase_samples2 = pd.Series(purchase_samples2)\n",
    "reorder_samples2 = pd.Series(reorder_samples2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_freq = purchase_samples2.value_counts()\n",
    "reorder_freq = reorder_samples2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        'Purchase': purchase_samples2,\n",
    "        'Reorder': reorder_samples2,\n",
    "\n",
    "    }\n",
    ").plot(\n",
    "    kind='kde',\n",
    "    title='Multinomial Distribution',\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conjugate distributions for posterior\n",
    "purchase = purchase_samples1 * purchase_samples2\n",
    "reorder = reorder_samples1 * reorder_samples2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        'Posterior Purchased Most': purchase,\n",
    "        'Posterior Reordered Most': reorder,\n",
    "    }\n",
    ").plot(\n",
    "    kind='kde',\n",
    "    title='Most Reordered Items vs Most Purchased Items ',\n",
    "   \n",
    ")\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Confidence level for the most reordered items differing from most purchased items ' + str (100 * ((purchase - reorder) > 0).mean().round(2)) + '%' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis has failed to have been rejected suggesting that there is no difference in the most purchased items and most reordered items likelihood."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
